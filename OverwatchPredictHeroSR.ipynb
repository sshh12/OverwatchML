{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from OverwatchProcessData import get_vector_herostats\n",
    "from OverwatchProcessData import get_competitive_rank, hero_stats\n",
    "from OverwatchGatherData import Player, find_usernames\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 145)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "\n",
    "specific_stats = {}\n",
    "\n",
    "for stat in hero_stats:\n",
    "    \n",
    "    hero, _, _ = stat.split(\" \")\n",
    "    \n",
    "    if hero in specific_stats:\n",
    "        \n",
    "        specific_stats[hero].append(stat)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        specific_stats[hero] = [stat]\n",
    "\n",
    "def generate_players():\n",
    "    \n",
    "    for filename in os.listdir('profiles'):\n",
    "        \n",
    "        player = Player.from_file(os.path.join('profiles', filename))\n",
    "        \n",
    "        if 'error' not in player.json:\n",
    "            \n",
    "            yield player\n",
    "\n",
    "def load_data(hero):\n",
    "\n",
    "    unscaled_X, unscaled_y = [], []\n",
    "\n",
    "    for player in generate_players():\n",
    "\n",
    "        rank = get_competitive_rank(player, 'us')\n",
    "\n",
    "        if rank:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                time_played = player.json['us']['heroes']['stats']['competitive'][hero]['general_stats']['time_played']\n",
    "                \n",
    "                if time_played >= .5:\n",
    "                \n",
    "                    unscaled_X.append(get_vector_herostats(player, 'us', stat_keys=specific_stats[hero]))\n",
    "                    unscaled_y.append(rank)\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                pass\n",
    "           \n",
    "\n",
    "    unscaled_X = np.array(unscaled_X, dtype=np.float64)\n",
    "    unscaled_y = np.array(unscaled_y, dtype=np.float64)\n",
    "    \n",
    "    print(unscaled_X.shape, unscaled_y.shape)\n",
    "    \n",
    "    return unscaled_X, unscaled_y\n",
    "\n",
    "len(specific_stats), len(specific_stats['mercy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale\n",
    "\n",
    "def scale_data(unscaled_X, unscaled_y):\n",
    "    \n",
    "    scaler_X = StandardScaler()\n",
    "\n",
    "    X = scaler_X.fit_transform(unscaled_X)\n",
    "    y = unscaled_y / 5000\n",
    "    \n",
    "    return X, y, scaler_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "def get_model(hero):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(18, input_dim=len(specific_stats[hero]), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(18, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(18, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(18, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(18, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train wrapper\n",
    "\n",
    "def train_model(model, *args, **kwargs):\n",
    "\n",
    "    history = model.fit(*args, **kwargs, shuffle=True, validation_split=.10, verbose=0, callbacks=[EarlyStopping(patience=25)])\n",
    "    \n",
    "    return history\n",
    "\n",
    "def get_hero_model(hero, from_file=False):\n",
    "    \n",
    "    if from_file:\n",
    "        \n",
    "        model = load_model(os.path.join('models', '{}-sr.h5'.format(hero)))\n",
    "        \n",
    "        scaler_X = joblib.load(os.path.join('models', '{}-sr.pkl'.format(hero)))\n",
    "        \n",
    "        return None, model, scaler_X\n",
    "    \n",
    "    print('TRAINING ' + hero)\n",
    "    \n",
    "    X, y, scaler_X = scale_data(*load_data(hero))\n",
    "\n",
    "    model = get_model(hero)\n",
    "\n",
    "    history = train_model(model, X, y, epochs=1000, batch_size=512)\n",
    "\n",
    "    model.save(os.path.join('models', '{}-sr.h5'.format(hero)))\n",
    "    joblib.dump(scaler_X, os.path.join('models', '{}-sr.pkl'.format(hero)))\n",
    "    \n",
    "    return history, model, scaler_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "def predict_sr(model, player, scaler_for_X, hero):\n",
    "    \n",
    "    stats_vector = np.array([get_vector_herostats(player, 'us', stat_keys=specific_stats[hero])])\n",
    "    \n",
    "    X = scaler_for_X.transform(stats_vector)\n",
    "\n",
    "    y_matrix = model.predict(X)\n",
    "    \n",
    "    sr = np.squeeze(y_matrix) * 5000\n",
    "    \n",
    "    return int(sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View\n",
    "\n",
    "def view(history):\n",
    "    \n",
    "    plt.plot(np.log(history.history['loss']))\n",
    "    plt.plot(np.log(history.history['val_loss']))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Log(loss)')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(np.sqrt(history.history['loss']) * 5000)\n",
    "    plt.plot(np.sqrt(history.history['val_loss']) * 5000)\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Avg Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylim([0, 1250])\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run\n",
    "\n",
    "for hero in specific_stats:\n",
    "    \n",
    "    history, model, _ = get_hero_model(hero)\n",
    "    \n",
    "    plt.plot(np.sqrt(history.history['val_loss']) * 5000)\n",
    "    \n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Avg Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0, 1300])\n",
    "plt.legend(list(specific_stats), loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load models from disk\n",
    "\n",
    "models = {}\n",
    "\n",
    "for hero in specific_stats:\n",
    "    \n",
    "    models[hero] = get_hero_model(hero, from_file=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict using all viable models\n",
    "\n",
    "def predict_all(player):\n",
    "    \n",
    "    sr_predictions = []\n",
    "    time_played = []\n",
    "\n",
    "    for hero in specific_stats:\n",
    "        \n",
    "        player_hero_stats = player.json['us']['heroes']['stats']['competitive']\n",
    "\n",
    "        if hero in player_hero_stats and player_hero_stats[hero]['general_stats']['time_played'] >= .5:\n",
    "\n",
    "            _, model, scaler = models[hero]\n",
    "                \n",
    "            sr_predictions.append(predict_sr(model, player, scaler, hero))\n",
    "            time_played.append(player_hero_stats[hero]['general_stats']['time_played'])\n",
    "                \n",
    "    return int(np.average(sr_predictions, weights=time_played))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "with open('test_names.txt', 'r') as test:\n",
    "\n",
    "    for battletag in find_usernames(test.read()):\n",
    "        \n",
    "        player = Player.from_web_battletag(battletag)\n",
    "        \n",
    "        actual = get_competitive_rank(player, 'us')\n",
    "        p = predict_all(player)\n",
    "        \n",
    "        print(\"{} is {}, predicted {}\".format(battletag, actual, p))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
